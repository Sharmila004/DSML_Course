{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c7ed59-5433-4f6a-a12c-869ebce6d99f",
   "metadata": {},
   "source": [
    "## Programming: \n",
    "* Providing instructions to perform certain tasks. it could be through a simple if-else block etc. in case of like, lets say finding the shortest path between 2 places.\n",
    "* Sometiumes it gets harder to describe the task to the computer in the form of simple set of instructions thus making it harder to tell machines what to do.  Like in case of telling it how to describe a cat, system doesnt kniw wht fur is, what a meow is etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6e30f-8f5c-4ed9-9bef-8d358a37d563",
   "metadata": {},
   "source": [
    "## Machine learning applications:\n",
    "\n",
    "* self driving cars\n",
    "* robots\n",
    "* language processing\n",
    "* vision processing\n",
    "* recommendation engines\n",
    "* translation services\n",
    "* stock price predictions\n",
    "\n",
    "earlier when technologies only evolved to support and enhance businness purposes and intensive works or tasks sometimes it got difficult to pragram the system to perform certain tasks. \n",
    "\n",
    "As time passed, things that computers couldnt do that humans could can now be done by computers with machine learning.\n",
    "\n",
    "primary goal: to make machines act more and more like humans \n",
    "reason: the smarter they get, the more they help humans accomplish their goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5fc8f-9b99-49b3-a404-b4f6f370d275",
   "metadata": {},
   "source": [
    "Artificial Intelligence: Human intelligence exhibited by the machines.\n",
    "\n",
    "Narrow AI (current): machines can be as good as or sometimes even better than umans at certain tasks. However each AI is only specialised at each specific task. they are not as good when it comes to multi tasking.\n",
    "\n",
    "General AI (future): machines can multitask like humans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9409dea-449c-48e6-b53b-ebff5bb584e9",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "* it is a subset of AI\n",
    "* it is an approach to try and achieve AI through systems that can find patterns in a set of data.\n",
    "* It is the science of getting computers to act without having to be explicitely programmed. i.e., getting machines to do things without us specifically saying do this, then do that and stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc9263-b909-44fa-acd6-4e3c5f12a36a",
   "metadata": {},
   "source": [
    "## Deep Learning/ deep neural networks\n",
    "one of the techniques of implemention ML. (A type of algorithm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b748b0c-3bb3-4639-b673-4e926b96345e",
   "metadata": {},
   "source": [
    "## Data Science\n",
    "looking and analysing data, and then doing something or manipulating to to meet business goals.\n",
    "\n",
    "for eg: looking into teh databvase to see the set of customers who have made more purchases during the winter. so now while telecalling the customers the team can focus only on the most probable winter customers thus making business much easir and more effecient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2106cca2-91be-409c-a331-1e0c5ef91ba2",
   "metadata": {},
   "source": [
    "## teacable machine:\n",
    "a google platform, a good free platform to understand ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f75298-5ad3-4583-b17f-bddd30b8f7b8",
   "metadata": {},
   "source": [
    "## Why Machine Learning\n",
    "* we are able to use machine to predict results based on incoming data\n",
    "* most technology evolves from business needs\n",
    "* spreadsheets (excel and csv): store data that business generates so that analysing becomes easier and so did business desicions\n",
    "* as company data increased, relatiuonal databases (sql) came into picture. storing, analysing, and retrieval of structured data became much easier despite the size of data.\n",
    "* in 2000s came big data, (nosql databases)(Unstructured), FB, Amazon, Twitter, Google had insanely big amount of data to be stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6abc5e-1969-4e33-9fac-542176986ac9",
   "metadata": {},
   "source": [
    "## Steps \n",
    "* Data Collecting\n",
    "* Data Modelling (ia an iterative process as a whole)\n",
    "  * Problem Defenition (what problem are we trying to solve)\n",
    "  * Data Analysis \n",
    "    * data (what data do we have)\n",
    "    * evaluation (what defines success)\n",
    "    * features (what feature should we model)\n",
    "  * Modelling (ML) (what kind of model should we use)\n",
    "  * Experiments (what have we tried/ what else can we try)\n",
    "* Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479147f-d4f4-4b76-b176-b1ad1c00df72",
   "metadata": {},
   "source": [
    "## Models <-> Training Models\n",
    "\n",
    "* ### Data Analysis:\n",
    "  looking at a set of data and understandig it by comparing different examples, different features, and make visualizations like graphs\n",
    "  \n",
    "* ### data science:\n",
    "  running sets of experiments on set of data with the hope of finding actionable insights within it. One such exp[eriment may be buiulding a machine learning model\n",
    "\n",
    "* note: data analysis and machine learning are a part of data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e436543-51de-46d1-a4a3-f72cafb6c227",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "3 types\n",
    "* Supervised\n",
    "  * subset of ML\n",
    "  * data that is received already has categories\n",
    "  * we have labelled data and test data\n",
    "  * eg: csv file with labelled rows and columns\n",
    "  * we can use classification or regression\n",
    "* Unsupervised\n",
    "  * data that is received doesnt have labells\n",
    "  * eg: csv filw without the column names labelled\n",
    "  * we can use clustering or association rule learning\n",
    "* Reinforcement\n",
    "  * teaching machines through trial and error\n",
    "  * this is seen  for skill acquisition or real time learning\n",
    "  * eg: vedio games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc4c48-1e3d-402f-a3ca-4d7522d141de",
   "metadata": {},
   "source": [
    "### When not to use ML\n",
    "question to ask: will a simple hand-coded instruction based system work?\n",
    "when yes, we need to favour the simpler system over the ML System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a1f18-1cb2-4c9e-8be4-59551de59793",
   "metadata": {},
   "source": [
    "# Building ML and DS framework: \n",
    "\n",
    "steps/template to cover in data modelling:\n",
    "\n",
    "* ## Create framework\n",
    "  \n",
    "  * ### problem defenition\n",
    "    * what problem are we trying to solve?\n",
    "    * is it supervised, unsupervised, calssification or regression problem?\n",
    "      \n",
    "  * ### data\n",
    "    * what data do we have?\n",
    "    * ML involves using algorithms to find and learn different patterns in data\n",
    "    * it could be\n",
    "      * structured data: like rows and columns\n",
    "      * unstructured data: like images and audios\n",
    "       \n",
    "  * ### evaluation\n",
    "    * what defines success to us?\n",
    "    * ML is experimental, so we could keep incrementaly improving or modifying to improve the results to arrive at perfectmodel (min 95% accurate)\n",
    "      \n",
    "  * ### features\n",
    "    * ehat do we already knowabout the data?\n",
    "    * even within different types of data, there are different kinds of features\n",
    "    * eg: heart disease prediction model may use patient's body weight as a feature. and since it is a number, it is called a numerical feature.\n",
    "      and model would predict according to if someone's weight is over a certain number, they are more likely to have heart disease.\n",
    "    * other egs: categorical and derived features\n",
    "      \n",
    "  * ### modelling\n",
    "    * based on our problem and data, what model should we use?\n",
    "    * most of useful ML algorithms have already been coded and some models may work better on different problems than others. so we need to figure out\n",
    "      the right model for the right kind of problem\n",
    "  \n",
    "  * ### experimentation\n",
    "    * how can we improve/ what can we do next?\n",
    "    * all the above 6 steps happen in a cycle and doesnt necessarily have to be from the top\n",
    "            \n",
    "* ## Match the framework to available DS and ML tools\n",
    "  * ### Anaconda\n",
    "    (hardware store)\n",
    "  * ### miniconda\n",
    "    (workbench)\n",
    "  * ### conda\n",
    "    (personal assistant)\n",
    "  * Anaconda and miniconda are software diostributions: when installed, it comes with code that other people have written that we can use. this\n",
    "    collection of code written by other people are nothing but the packages/tools.\n",
    "  * conda is the package manager\n",
    "  * While anaconda has all the possibly necessary tools for Data Science and Machine Learning\n",
    "  * miniconda on the other hand has all the required (satify basic requirement) 'to-get-started' tools like python and few others and takes about 10\n",
    "    times less space compared to anaconda\n",
    "  * conda is like the assistant and help u manage and share environments where we save out packages/tools\n",
    "  * once the miniconda is downloaded and installed, itll have a few tools and conda helps you manage those tools.\n",
    "  \n",
    "* ## learn by doing\n",
    "  * ### Windows environment setup\n",
    "    * #### Anaconda\n",
    "    * * Download Anaconda\n",
    "      * Install in computer\n",
    "      * test installation (conda list)\n",
    "      * load up jupyter notebook\n",
    "      * import numpy, pandas, matplotlib, sklearn\n",
    "    * #### Miniconda\n",
    "    * * Download miniconda\n",
    "      * install in computer\n",
    "      * test installation via terminal\n",
    "      * create project folder and enter it\n",
    "      * create custom (env) environment within the project folder\n",
    "      * activate env (conda activate \"path of env\")\n",
    "      * install jupyter (conda install jupyter)\n",
    "      * load up a jupyter notebook and check the tools you need (jupyter notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a811f-f0c1-4859-9638-c9269a387cdb",
   "metadata": {},
   "source": [
    "## Step-1: Problem Defenition\n",
    "identifying and matching our problems with the main types of ML Problems: (first 3 are most common)\n",
    "* ### Supervised Learning\n",
    "  * we have data and labels where we can use algorithms that try and use the data to predict the labels. if the algorithm spredicts teh label wrong, it\n",
    "    reexecutes and corrects itself and then predict again\n",
    "  * self-correction is the key feature\n",
    "  * main types are classification and regression:\n",
    "    * #### classification\n",
    "      * predict if something is one thing or another\n",
    "        * like whether a patient has heart disease or not (here chosed among 2 options: binary classification)\n",
    "        * like type of dog breed in an image (more thn one possiblility/choices: multiclass classification)\n",
    "    * #### regression\n",
    "      * predict a number/ a continuous number (goesup an down)\n",
    "      * like predict sales price of a house based on the things like no. of rooms, area it is put up, no. of bathrooms, no of people who are willing to\n",
    "        buy(demand) etc.\n",
    "* ### unsupervised learning\n",
    "    * we come up with labels, it was not there when we began with, but there was a pattern which the ML model had formed\n",
    "    * problems like this are also called clustering: putting group of similar exampls/ features togeather\n",
    "    * like in a sales company, get and retrieve data of customers buying clothes in winter and summer and then label them as winter customers and summer\n",
    "      customers and winter customers respectively.\n",
    "    * example: recommendation problems such as recommending what music someone should listen to based on their previous music choices often start out\n",
    "        as unsupervised  \n",
    "* ### transfer learning\n",
    "  * leverages what one ML model has learned in another ML model\n",
    "  * like predicting a dog breed model. and let's say there is an existing model which has learned to predict cars. this model can be fine tuned for our\n",
    "    task to predict dog breeds. because it would have already had its foundational training & can detect & ignore things to be ignored (which it is\n",
    "    alreadt aware of) like grass, trees etc\n",
    "* ### reinforcement learning\n",
    "  * having a computer program perform some actions within a space and rewarding it for doing well or punishing it for doing poorly.\n",
    "  * chess game: on teaching an ML Algorithm toplay chess,\n",
    "    * chess board: the devine space\n",
    "    * moving peice: the actions\n",
    "    * rewards: +1 score\n",
    "    * punishment: -1 score\n",
    "   \n",
    "### conclusively \n",
    "matching your problem with the ML problems:\n",
    "* supervised learning\n",
    "  * i know my inputs and outputs\n",
    "* unsupervised learning\n",
    "  * im not sure of the outputs but i have inputs\n",
    "* transfer learning\n",
    "  * i think my problem may be similar to something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29370a2-3265-44e4-891d-003b71c322c5",
   "metadata": {},
   "source": [
    "## Step-2: Data\n",
    "* the data can b broadly classified as structured or unstructured\n",
    "* the data can also be classified as static and streaming\n",
    "  * static\n",
    "    * doesnt change over time\n",
    "    * eg: csv(comma separated values), excel\n",
    "  * streaming\n",
    "    * constantky changes over time\n",
    "    * eg: news headlines, stock updates\n",
    "* ### data science workflow\n",
    "  * CSV (static data)\n",
    "  * Jupyter Notebook (tool for building ML Project)\n",
    "  * Data Analysis - Pandas (exploring data and performing data analysis)\n",
    "  * Visualizations/Graphs - Matplotlib (comparing different data points)\n",
    "  * ML Model - psychic learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258bf3a-0684-423c-9bcd-845b55e94dac",
   "metadata": {},
   "source": [
    "## Step-3: Evaluation\n",
    "* ### Evaluation Metric\n",
    "  * measure of accuracy\n",
    "  * measure of how well an ML algorithm predicts the future\n",
    "* types of metrics:\n",
    "  * there are different evaluation metrics for different problems\n",
    "  * CLassification\n",
    "    * Accurace, Precision, Recall\n",
    "  * Regression\n",
    "    * Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE)\n",
    "  * Recommendation\n",
    "    * Precision at K "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016a0f0-0bac-4b9e-a47b-30d9e804db9f",
   "metadata": {},
   "source": [
    "## Step-4: Features\n",
    "* features ois another word for different forms of data\n",
    "* features refer to teh different forms of data within structured or unstructured data\n",
    "* Structured data eg:\n",
    "  * like in heart disease problem, considerable parameters to determine yes/no include\n",
    "    * person's body weight\n",
    "    * sex\n",
    "    * average resting heart rate\n",
    "    * chest pain ratings\n",
    "* Unstructured data eg:\n",
    "  * consider images of dogs, it could be the different shapes.\n",
    "* these are referred to as features/ feature variables\n",
    "* feature variables are used to predict target variable (whether the person has heart disease(output))\n",
    "* ### feature variabloes\n",
    "  * numerical\n",
    "    * numbers (body weight)\n",
    "  * categorical\n",
    "    * one/ another (sex)\n",
    "  * derived\n",
    "    * a new feature created on analysing existing data/features (on looking at history timestamps like IDs, we can derive at  afeature called 'visited\n",
    "      in last year')\n",
    "    * applicable in refernce to feature engineering\n",
    "* ### What feature should we use:\n",
    "  * want >90% coverage\n",
    "  * if the most eaten food feature only have 10/100 records, then it is best to not to include the dataset or collect more data before including."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af067288-e7bc-408b-9486-e05c5ce97800",
   "metadata": {},
   "source": [
    "## Step-5: Modelling\n",
    "### Part-1: 3 sets\n",
    "* The datset is split into 3 sets for modelling (The train, validation and test splits):\n",
    "  * Training set\n",
    "    * (70-80)% split\n",
    "    * Choosing and training a model \n",
    "  * Tuning a model\n",
    "    * (10-15)% split\n",
    "    * Validation set\n",
    "  * Model Comparision\n",
    "    *(10-15)% split\n",
    "    * Test and complete\n",
    "* eg: patients dataset has 100 records, then lets say 70 records are split for training, 15 for tuning and 15 for testing.\n",
    "### Part-2: Choosing and Training\n",
    "* There are many prebuilt ML Models which we can choose an dtake advantage of instead of coming up with our own algorithm from scratch\n",
    "* goal: know what kind of ML algorithm to use with what kidn of problem\n",
    "* R: some algorithms work better than others on different types of data\n",
    "* example for structured data:\n",
    "  * decision trees such as random forest and gradient booting algorithms like cat boot and XG boost tend to work best\n",
    "* examplpe for unstructured dat:\n",
    "  * deep learning neural networks and transfer learning tend to work best.\n",
    "* trrain model to perform according to problem so it takes the available feature variables to arrive at target variables or use X(data) to predict Y(label)\n",
    "### Part-3: Tuning\n",
    "* takes place in validation set\n",
    "* tune existing trained model with different data with your data\n",
    "* when we dont have access to validation dat set and test-data split, then it can be done with the training data set\n",
    "### Note:\n",
    "* kind of model depends m kind of hyper parameters\n",
    "* adjustment acc to different kinds of algorithms:\n",
    "  * random trees allow us to use different number of layers\n",
    "  * neural networks allow us to ise differnet number of layers\n",
    "### Part-4: Model Comparision\n",
    "* done on test dat\n",
    "* compare different model acc to hyper parameter tuned model\n",
    "* Overfitting\n",
    "  * when performace(Training data-set) > performance(test-set).\n",
    "  * model has learned well and fits all data points but too close.\n",
    "* Underfitting\n",
    "  * when performance(test-set) > performance(training data-set).\n",
    "  * data points kind of fit the shape\n",
    "* Goldilock zone\n",
    "  * ideal models show up in this zone\n",
    "  * fits perfectly\n",
    "  * iterative, balanced model\n",
    "* Reasons for pverfittinga nd underfitting\n",
    "  * data leakage: test data leaks into the training data\n",
    "  * data mismatch: training data is different from test data\n",
    "* Mitigations against overfitting and underfitting\n",
    "  * ensure that either validation or taining data set is used for validation & model tuning\n",
    "  * ensure that test data set is used for testing an dmodel comparision\n",
    "* fixes for underfitting\n",
    "  * using a more advanced model / by changing entire model\n",
    "  * increase no of hyper parameters on current model\n",
    "  * reduce amount of features: model may find it difficult to learn when ther are too many features\n",
    "  * train longer\n",
    "* fixes for overftting\n",
    "  * collect more data: more data <=> more petoential patterns <=> lesserpotential to find\n",
    "  * try less advanced model (uncommon): sometimes when models are too good -> incorrect prediction\n",
    " \n",
    "## Step-6: Experimentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
